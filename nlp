1. Using spaCy

    With Anaconda add spaCy to your env.
    or
$ conda activate <env>
$ conda install -c conda-forge spacy
$ python -m spacy info

  From: https://spacy.io/usage/models
$ python -m spacy download en_core_web_sm
>>> import spacy
>>> nlp = spacy.load("en_core_web_sm")

(some problems downloading the small model and then using similarity. Download the large model.)

$ python -m spacy download en_core_web_lg
>>> nlp = spacy.load("en_core_web_lg")
>>> nlp("dog").similarity(nlp("animal"))

text = "Wait till you hear this!"
doc = nlp(text)
for token in doc:               # source: https://course.spacy.io
    # Get the token text, part-of-speech tag and dependency label
    token_text = token.text
    token_pos = token.pos_
    token_dep = token.dep_
    # This is for formatting only
    print(f"{token_text:<12}{token_pos:<10}{token_dep:<10}")
for ent in doc.ents:
    # Print the entity text and its label
    print(ent.text, ent.label)
some_span = doc[1:3]
print(some_span.text)

>>> from spacy.matcher import Matcher
matcher = Matcher(nlp.vocab)
pattern = [
    {"TEXT": "iPhone", "POS": "DET", "OP": "?",} ,      #these three requirements for the first token match
    {"TEXT": "X"}                                       #one more requirement for the next token match
]
matcher.add("some arbitrary name", None, pattern)
matches = matcher(doc)

>>> from spacy.lang.en import English
>>> nlp = English()
or
>>> import spacy
>>> nlp = spacy.load("en_core_web_lg")
THEN you can obtain the internal hash used for cat in the two-way lookup StringStore table
cat_hash = nlp.vocab.strings["cat"]
cat_string = nlp.vocab.strings[cat_hash]

>>> nlp.vocab.strings["PERSON"]
380
>>> nlp.vocab.strings["person"]
14800503047316267216

# doc exposes vocab also, but basically points to the nlp vocab
>>> print ( len (doc.vocab.strings))
1476045
>>> print ( len (nlp.vocab.strings))
1476045
>>> print ( id (nlp.vocab.strings))
5571244880
>>> print ( id (doc.vocab.strings))
5571244880

from spacy.tokens import Doc, Span
#create a Doc from scratch
words = ["California", "is", "sunny", "!"]
spaces = [True, True, False, False]         # or spaces = None, to give space to all tokens
# Create a Doc from the words and spaces
doc = Doc(nlp.vocab, words=words, spaces=spaces)

doc = nlp("California is a state.")
span = Span(doc, 0, 1, label = "PNOUN")
# Add the span to the doc's entities
doc.ents = [span]
print([(ent.text, ent.label_) for ent in doc.ents])

>>> doc[0].vector
array([-3.0439e-01,  4.9227e-01, -7.6365e-02, -7.5354e-01,  5.8803e-01,
..
       -2.5008e-01,  3.6174e-01, -6.3967e-01,  6.6353e-02,  5.3749e-01],
      dtype=float32)
>>>

#Two different ways to get spans
span1 = Span(doc, 3, 5)
span2 = doc[-4:-1]
print (span1, "similarity to",  span2)
# Get the similarity of the spans
print (span1.similarity(span2))
