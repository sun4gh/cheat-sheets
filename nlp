1. Using spaCy

    With Anaconda add spaCy to your env.
    or
$ conda activate <env>
$ conda install -c conda-forge spacy
$ python -m spacy info

  From: https://spacy.io/usage/models
$ python -m spacy download en_core_web_sm
>>> import spacy
>>> nlp = spacy.load("en_core_web_sm")

(some problems downloading the small model and then using similarity. Download the large model.)

$ python -m spacy download en_core_web_lg
>>> nlp = spacy.load("en_core_web_lg")
>>> nlp("dog").similarity(nlp("animal"))

text = "Wait till you hear this!"
doc = nlp(text)
for token in doc:               # source: https://course.spacy.io
    # Get the token text, part-of-speech tag and dependency label
    token_text = token.text
    token_pos = token.pos_
    token_dep = token.dep_
    # This is for formatting only
    print(f"{token_text:<12}{token_pos:<10}{token_dep:<10}")
for ent in doc.ents:
    # Print the entity text and its label
    print(ent.text, ent.label)
some_span = doc[1:3]
print(some_span.text)

>>> from spacy.matcher import Matcher
matcher = Matcher(nlp.vocab)
pattern = [
    {"TEXT": "iPhone", "POS": "DET", "OP": "?",} ,      #these three requirements for the first token match
    {"TEXT": "X"}                                       #one more requirement for the next token match
]
matcher.add("some arbitrary name", None, pattern)
matches = matcher(doc)

>>> from spacy.lang.en import English
>>> nlp = English()
or
>>> import spacy
>>> nlp = spacy.load("en_core_web_lg")
THEN you can obtain the internal hash used for cat in the two-way lookup StringStore table
cat_hash = nlp.vocab.strings["cat"]
cat_string = nlp.vocab.strings[cat_hash]

>>> nlp.vocab.strings["PERSON"]
380
>>> nlp.vocab.strings["person"]
14800503047316267216

# doc exposes vocab also, but basically points to the nlp vocab
>>> print ( len (doc.vocab.strings))
1476045
>>> print ( len (nlp.vocab.strings))
1476045
>>> print ( id (nlp.vocab.strings))
5571244880
>>> print ( id (doc.vocab.strings))
5571244880

